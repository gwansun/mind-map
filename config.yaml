chroma:
  collection_name: mind_map_nodes
  embedding_model: nomic-embed-text
graph:
  default_depth: 2
  max_connections: 50
importance:
  lambda_decay: 0.05
  time_unit: days
processing_llm:
  provider: ollama          # auto | gemini | anthropic | openai | ollama
  auto_pull: false
  model: phi3.5           # Ollama model (used when provider is ollama or auto-fallback)
  temperature: 0.1
reasoning_llm:
  provider: claude-cli  # Options: claude-cli, gemini, anthropic, openai
  model: sonnet         # For claude-cli: sonnet, opus, haiku
  temperature: 0.7
  timeout: 120          # Timeout in seconds for CLI calls

# Alternative configurations:
# reasoning_llm:
#   provider: gemini
#   model: gemini-1.5-pro
#   temperature: 0.7
#
# reasoning_llm:
#   provider: anthropic
#   model: claude-sonnet-4-5-20250929
#   temperature: 0.7
#
# reasoning_llm:
#   provider: openai
#   model: gpt-4o
#   temperature: 0.7
